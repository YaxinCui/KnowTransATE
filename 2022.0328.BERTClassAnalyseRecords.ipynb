{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CollateFn.CollateFnBase import CollateFnBase\n",
    "\n",
    "CollateFnBase.id2label = CollateFnBase.ATEid2label\n",
    "CollateFnBase.label2id = CollateFnBase.ATElabel2id\n",
    "\n",
    "from ModelSummary.ModelOutputsRecord import ModelOutputsRecord\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairMap:\n",
    "    def __init__(self, logDir='./RecordsDir/') -> None:\n",
    "        self.logDir = logDir\n",
    "        self.recordsPath = os.listdir(logDir)\n",
    "        self.modelRecords = []\n",
    "        self.analyseModelResults = []\n",
    "\n",
    "        self.languages =['english', 'spanish', 'french']\n",
    "        self.languageArrgs = {\n",
    "            'english': 'En', \n",
    "            'spanish': 'Es', \n",
    "            'french': 'Fr'\n",
    "        }\n",
    "        self.arrgs = ['En', 'Es', 'Fr']\n",
    "\n",
    "        self.loadDir()\n",
    "\n",
    "    def loadDir(self):\n",
    "        for recordPath in self.recordsPath:\n",
    "            if recordPath[-1] == 's':\n",
    "                modelRecord = ModelOutputsRecord.load(self.logDir +'/' + recordPath)\n",
    "                # print('load ' + self.logDir + recordPath)\n",
    "                self.modelRecords.append(modelRecord)\n",
    "                analyseModelResult = modelRecord.analyseModel()\n",
    "                analyseModelResult['source'] = self.languageArrgs[modelRecord.dataParams.Source]\n",
    "                self.analyseModelResults.append(analyseModelResult)\n",
    "            \n",
    "    def analyse(self, key=\"MacroF1\"):\n",
    "        # 要分析出均值和方差\n",
    "        source2targetResults = {}\n",
    "        for source in self.arrgs[:1]:\n",
    "            for target in self.arrgs:\n",
    "                source2targetResults[f\"{source}2{target}\"] = []\n",
    "        \n",
    "        for analyseModelResult in self.analyseModelResults:\n",
    "            for target in self.arrgs:\n",
    "                source2targetResults[f\"{analyseModelResult['source']}2{target}\"].append(analyseModelResult[f'test{target}'][key])\n",
    "\n",
    "        \n",
    "        analyseDic = {}\n",
    "        for key, valueList in source2targetResults.items():\n",
    "            analyseDic[key] = (np.round(np.mean(valueList)*100, 3), np.round(np.std(valueList)*100, 3), len(valueList))\n",
    "\n",
    "        return pd.DataFrame(analyseDic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xlm-roberta-base类\n",
    "    Records/cardiffnlp/twitter-xlm-roberta-base-sentiment\n",
    "    Records/CodeNinja1126/xlm-roberta-large-kor-mrc\n",
    "    Records/xlm-roberta-base\n",
    "    Records/xlm-roberta-base-yelp-mlm\n",
    "# xlm-roberta-large类\n",
    "    Records/xlm-roberta-large\n",
    "    Records/xlm-roberta-large-finetuned-conll02-spanish\n",
    "    Records/xlm-roberta-large-finetuned-conll03-english\n",
    "# mBert类\n",
    "    Records/bert-base-multilingual-uncased\n",
    "    Records/dbmdz/bert-base-multilingual-cased-finetuned-conll03-spanish\n",
    "    Records/nlptown/bert-base-multilingual-uncased-sentiment\n",
    "# roberta-base类\n",
    "    Records/allenai/reviews_roberta_base\n",
    "    Records/cardiffnlp/twitter-roberta-base-sentiment\n",
    "    Records/roberta-base\n",
    "# roberta-large类\n",
    "    Records/roberta-large\n",
    "    Records/this-is-real/mrc-pretrained-roberta-large-1\n",
    "# albert类\n",
    "    Records/albert-base-v2\n",
    "# bert-base类\n",
    "    Records/activebus/BERT_Review\n",
    "    Records/activebus/BERT-XD_Review\n",
    "    Records/ainize/klue-bert-base-mrc\n",
    "    Records/bert-base-uncased\n",
    "    Records/bert-large-uncased\n",
    "    Records/google/rembert\n",
    "    Records/skimai/spanberta-base-cased-ner-conll02\n",
    "    Records/SpanBERT/spanbert-base-cased\n",
    "# bert-large类\n",
    "# electra-base类\n",
    "    Records/dbmdz/electra-base-french-europeana-cased-generator\n",
    "    Records/electra-base-discriminator-yelp-mlm\n",
    "    Records/google/electra-base-discriminator\n",
    "# electra-small类\n",
    "    Records/google/electra-small-discriminator\n",
    "    Records/test-electra-small-yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records/cardiffnlp/twitter-xlm-roberta-base-sentiment\n",
      "    En2En   En2Es   En2Fr\n",
      "0  78.818  71.862  67.244\n",
      "1   0.554   1.605   1.503\n",
      "2   6.000   6.000   6.000\n",
      "\n",
      "Records/CodeNinja1126/xlm-roberta-large-kor-mrc\n",
      "    En2En   En2Es   En2Fr\n",
      "0  82.893  77.793  73.931\n",
      "1   0.871   0.305   0.965\n",
      "2   3.000   3.000   3.000\n",
      "\n",
      "Records/xlm-roberta-base\n",
      "    En2En   En2Es   En2Fr\n",
      "0  80.199  74.029  69.123\n",
      "1   2.060   1.060   1.457\n",
      "2   3.000   3.000   3.000\n",
      "\n",
      "Records/xlm-roberta-base-yelp-mlm\n",
      "    En2En   En2Es   En2Fr\n",
      "0  81.915  70.275  68.742\n",
      "1   0.243   1.115   2.589\n",
      "2   3.000   3.000   3.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xlm-roberta-base类\n",
    "# 模型层数量,ndim数量，模型大小\n",
    "paths = [\n",
    "    \"Records/cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "    \"Records/CodeNinja1126/xlm-roberta-large-kor-mrc\",\n",
    "    \"Records/xlm-roberta-base\",\n",
    "    \"Records/xlm-roberta-base-yelp-mlm\"\n",
    "]\n",
    "rList = []\n",
    "for path in paths:\n",
    "    pairMap = PairMap(path)\n",
    "    analysePd = pairMap.analyse()\n",
    "    rList.append(analysePd)\n",
    "\n",
    "for path, record in zip(paths, rList):\n",
    "    print(path)\n",
    "    print(record)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records/xlm-roberta-large\n",
      "    En2En   En2Es   En2Fr\n",
      "0  81.845  76.662  73.922\n",
      "1   0.122   0.995   0.715\n",
      "2   3.000   3.000   3.000\n",
      "\n",
      "Records/xlm-roberta-large-finetuned-conll02-spanish\n",
      "    En2En   En2Es   En2Fr\n",
      "0  83.593  75.968  73.206\n",
      "1   0.703   1.694   0.399\n",
      "2   3.000   3.000   3.000\n",
      "\n",
      "Records/xlm-roberta-large-finetuned-conll03-english\n",
      "    En2En   En2Es   En2Fr\n",
      "0  82.469  77.002  73.523\n",
      "1   0.973   1.113   1.056\n",
      "2   3.000   3.000   3.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xlm-roberta-large类\n",
    "\n",
    "paths = [\n",
    "    \"Records/xlm-roberta-large\",\n",
    "    \"Records/xlm-roberta-large-finetuned-conll02-spanish\",\n",
    "    \"Records/xlm-roberta-large-finetuned-conll03-english\"\n",
    "]\n",
    "rList = []\n",
    "for path in paths:\n",
    "    pairMap = PairMap(path)\n",
    "    analysePd = pairMap.analyse()\n",
    "    rList.append(analysePd)\n",
    "\n",
    "for path, record in zip(paths, rList):\n",
    "    print(path)\n",
    "    print(record)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records/bert-base-multilingual-uncased\n",
      "    En2En   En2Es   En2Fr\n",
      "0  77.113  67.652  62.266\n",
      "1   0.108   0.864   0.716\n",
      "2   3.000   3.000   3.000\n",
      "\n",
      "Records/dbmdz/bert-base-multilingual-cased-finetuned-conll03-spanish\n",
      "    En2En   En2Es   En2Fr\n",
      "0  75.722  65.755  62.417\n",
      "1   1.144   2.528   1.407\n",
      "2   3.000   3.000   3.000\n",
      "\n",
      "Records/nlptown/bert-base-multilingual-uncased-sentiment\n",
      "    En2En   En2Es   En2Fr\n",
      "0  76.131  67.721  62.293\n",
      "1   1.343   2.066   2.206\n",
      "2   7.000   7.000   7.000\n",
      "\n",
      "Records/google/rembert\n",
      "    En2En   En2Es   En2Fr\n",
      "0  81.092  76.544  73.413\n",
      "1   0.635   0.473   0.514\n",
      "2   3.000   3.000   3.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mBert类\n",
    "\n",
    "paths = [\n",
    "    \"Records/bert-base-multilingual-uncased\",\n",
    "    \"Records/dbmdz/bert-base-multilingual-cased-finetuned-conll03-spanish\",\n",
    "    \"Records/nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    \"Records/google/rembert\" # 彷佛是大模型\n",
    "]\n",
    "rList = []\n",
    "for path in paths:\n",
    "    pairMap = PairMap(path)\n",
    "    analysePd = pairMap.analyse()\n",
    "    rList.append(analysePd)\n",
    "\n",
    "for path, record in zip(paths, rList):\n",
    "    print(path)\n",
    "    print(record)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records/allenai/reviews_roberta_base\n",
      "    En2En   En2Es   En2Fr\n",
      "0  79.256  40.759  34.530\n",
      "1   0.493   3.723   2.573\n",
      "2   3.000   3.000   3.000\n",
      "\n",
      "Records/cardiffnlp/twitter-roberta-base-sentiment\n",
      "    En2En   En2Es   En2Fr\n",
      "0  81.646  27.180  31.201\n",
      "1   0.522   6.396   4.695\n",
      "2   5.000   5.000   5.000\n",
      "\n",
      "Records/roberta-base\n",
      "    En2En   En2Es   En2Fr\n",
      "0  80.396  41.533  39.471\n",
      "1   0.430   8.897   4.306\n",
      "2   3.000   3.000   3.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# roberta-base类\n",
    "\n",
    "paths = [\n",
    "    \"Records/allenai/reviews_roberta_base\",\n",
    "    \"Records/cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "    \"Records/roberta-base\"\n",
    "]\n",
    "rList = []\n",
    "for path in paths:\n",
    "    pairMap = PairMap(path)\n",
    "    analysePd = pairMap.analyse()\n",
    "    rList.append(analysePd)\n",
    "\n",
    "for path, record in zip(paths, rList):\n",
    "    print(path)\n",
    "    print(record)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records/roberta-large\n",
      "    En2En   En2Es   En2Fr\n",
      "0  81.269  64.335  56.028\n",
      "1   1.518   2.776   4.131\n",
      "2   3.000   3.000   3.000\n",
      "\n",
      "Records/this-is-real/mrc-pretrained-roberta-large-1\n",
      "    En2En   En2Es   En2Fr\n",
      "0  70.529  17.274  18.594\n",
      "1   0.000   0.000   0.000\n",
      "2   1.000   1.000   1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# roberta-large类\n",
    "paths = [\n",
    "    \"Records/roberta-large\",\n",
    "    \"Records/this-is-real/mrc-pretrained-roberta-large-1\"\n",
    "]\n",
    "rList = []\n",
    "for path in paths:\n",
    "    pairMap = PairMap(path)\n",
    "    analysePd = pairMap.analyse()\n",
    "    rList.append(analysePd)\n",
    "\n",
    "for path, record in zip(paths, rList):\n",
    "    print(path)\n",
    "    print(record)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records/albert-base-v2\n",
      "    En2En  En2Es   En2Fr\n",
      "0  78.604  3.838  21.421\n",
      "1   1.186  1.669   6.987\n",
      "2   5.000  5.000   5.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# albert类\n",
    "    \n",
    "paths = [\n",
    "    \"Records/albert-base-v2\"\n",
    "]\n",
    "rList = []\n",
    "for path in paths:\n",
    "    pairMap = PairMap(path)\n",
    "    analysePd = pairMap.analyse()\n",
    "    rList.append(analysePd)\n",
    "\n",
    "for path, record in zip(paths, rList):\n",
    "    print(path)\n",
    "    print(record)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records/activebus/BERT_Review\n",
      "    En2En   En2Es   En2Fr\n",
      "0  81.839  10.122  33.155\n",
      "1   0.600   1.926   2.137\n",
      "2   3.000   3.000   3.000\n",
      "\n",
      "Records/activebus/BERT-XD_Review\n",
      "    En2En   En2Es   En2Fr\n",
      "0  80.277  19.476  39.780\n",
      "1   0.242  10.392   2.884\n",
      "2   3.000   3.000   3.000\n",
      "\n",
      "Records/ainize/klue-bert-base-mrc\n",
      "    En2En  En2Es   En2Fr\n",
      "0  71.171  9.402  15.881\n",
      "1   0.200  1.464   2.686\n",
      "2   3.000  3.000   3.000\n",
      "\n",
      "Records/bert-base-uncased\n",
      "    En2En  En2Es  En2Fr\n",
      "0  77.765  0.902  15.95\n",
      "1   1.027  0.883   2.65\n",
      "2   3.000  3.000   3.00\n",
      "\n",
      "Records/skimai/spanberta-base-cased-ner-conll02\n",
      "    En2En   En2Es   En2Fr\n",
      "0  68.608  42.478  28.412\n",
      "1   2.193  24.963   1.251\n",
      "2   3.000   3.000   3.000\n",
      "\n",
      "Records/SpanBERT/spanbert-base-cased\n",
      "    En2En  En2Es   En2Fr\n",
      "0  75.627  4.028  16.463\n",
      "1   0.994  2.350   3.116\n",
      "2   3.000  3.000   3.000\n",
      "\n",
      "Records/Tahsin/BERT-finetuned-conll2003-POS\n",
      "    En2En  En2Es   En2Fr\n",
      "0  77.471  8.455  16.677\n",
      "1   0.642  3.863   1.052\n",
      "2   3.000  3.000   3.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bert-base类\n",
    "\n",
    "paths = [\n",
    "    \"Records/activebus/BERT_Review\",\n",
    "    \"Records/activebus/BERT-XD_Review\",\n",
    "    \"Records/ainize/klue-bert-base-mrc\",\n",
    "    \"Records/bert-base-uncased\",\n",
    "    \"Records/skimai/spanberta-base-cased-ner-conll02\",\n",
    "    \"Records/SpanBERT/spanbert-base-cased\",\n",
    "    \"Records/Tahsin/BERT-finetuned-conll2003-POS\"\n",
    "]\n",
    "rList = []\n",
    "for path in paths:\n",
    "    pairMap = PairMap(path)\n",
    "    analysePd = pairMap.analyse()\n",
    "    rList.append(analysePd)\n",
    "\n",
    "for path, record in zip(paths, rList):\n",
    "    print(path)\n",
    "    print(record)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records/bert-large-uncased\n",
      "    En2En   En2Es   En2Fr\n",
      "0  78.571  16.101  28.883\n",
      "1   0.973   8.591   6.349\n",
      "2   3.000   3.000   3.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bert-large类\n",
    "paths = [\n",
    "    \"Records/bert-large-uncased\"\n",
    "]\n",
    "rList = []\n",
    "for path in paths:\n",
    "    pairMap = PairMap(path)\n",
    "    analysePd = pairMap.analyse()\n",
    "    rList.append(analysePd)\n",
    "\n",
    "for path, record in zip(paths, rList):\n",
    "    print(path)\n",
    "    print(record)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records/albert-base-v2\n",
      "    En2En  En2Es   En2Fr\n",
      "0  78.604  3.838  21.421\n",
      "1   1.186  1.669   6.987\n",
      "2   5.000  5.000   5.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# albert类\n",
    "    \n",
    "paths = [\n",
    "    \"Records/albert-base-v2\"\n",
    "]\n",
    "rList = []\n",
    "for path in paths:\n",
    "    pairMap = PairMap(path)\n",
    "    analysePd = pairMap.analyse()\n",
    "    rList.append(analysePd)\n",
    "\n",
    "for path, record in zip(paths, rList):\n",
    "    print(path)\n",
    "    print(record)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records/dbmdz/electra-base-french-europeana-cased-generator\n",
      "    En2En   En2Es   En2Fr\n",
      "0  63.907  19.191  45.311\n",
      "1   1.778   1.688   1.290\n",
      "2   3.000   3.000   3.000\n",
      "\n",
      "Records/electra-base-discriminator-yelp-mlm\n",
      "    En2En  En2Es   En2Fr\n",
      "0  80.817  7.799  34.348\n",
      "1   0.831  7.949   5.876\n",
      "2   3.000  3.000   3.000\n",
      "\n",
      "Records/google/electra-base-discriminator\n",
      "    En2En  En2Es   En2Fr\n",
      "0  80.558  8.084  27.262\n",
      "1   1.088  5.154   8.196\n",
      "2   3.000  3.000   3.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# electra-base类\n",
    "paths = [\n",
    "    \"Records/dbmdz/electra-base-french-europeana-cased-generator\",\n",
    "    \"Records/electra-base-discriminator-yelp-mlm\",\n",
    "    \"Records/google/electra-base-discriminator\"\n",
    "]\n",
    "rList = []\n",
    "for path in paths:\n",
    "    pairMap = PairMap(path)\n",
    "    analysePd = pairMap.analyse()\n",
    "    rList.append(analysePd)\n",
    "\n",
    "for path, record in zip(paths, rList):\n",
    "    print(path)\n",
    "    print(record)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records/google/electra-small-discriminator\n",
      "    En2En  En2Es   En2Fr\n",
      "0  76.649  2.943  16.686\n",
      "1   1.314  1.504   2.620\n",
      "2   3.000  3.000   3.000\n",
      "\n",
      "Records/test-electra-small-yelp\n",
      "    En2En  En2Es   En2Fr\n",
      "0  79.137  6.270  24.254\n",
      "1   0.333  2.229   1.056\n",
      "2   3.000  3.000   3.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# electra-small类\n",
    "    \n",
    "        \n",
    "paths = [\n",
    "    \"Records/google/electra-small-discriminator\",\n",
    "    \"Records/test-electra-small-yelp\"\n",
    "]\n",
    "rList = []\n",
    "for path in paths:\n",
    "    pairMap = PairMap(path)\n",
    "    analysePd = pairMap.analyse()\n",
    "    rList.append(analysePd)\n",
    "\n",
    "for path, record in zip(paths, rList):\n",
    "    print(path)\n",
    "    print(record)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09adf8f92ca05d146ea9895e6b1b9eff578f52088b44cd8735948b784e1f3f68"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('cui': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
